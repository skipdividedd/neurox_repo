{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nseed = 7\nos.environ['PYTHONHASHSEED']=str(seed)\nos.environ[\"CUBLAS_WORKSPACE_CONFIG\"]=\":4096:8\" \nos.environ[\"CUDA_LAUNCH_BLOCKING\"]=\"1\" ","metadata":{"execution":{"iopub.status.busy":"2023-02-23T02:31:26.273746Z","iopub.execute_input":"2023-02-23T02:31:26.274063Z","iopub.status.idle":"2023-02-23T02:31:26.279225Z","shell.execute_reply.started":"2023-02-23T02:31:26.274041Z","shell.execute_reply":"2023-02-23T02:31:26.278264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git clone https://github.com/fdalvi/NeuroX","metadata":{"execution":{"iopub.status.busy":"2023-02-23T02:31:26.281420Z","iopub.execute_input":"2023-02-23T02:31:26.282119Z","iopub.status.idle":"2023-02-23T02:31:26.563279Z","shell.execute_reply.started":"2023-02-23T02:31:26.282092Z","shell.execute_reply":"2023-02-23T02:31:26.561671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\npackage_paths = [\n    '/kaggle/working/NeuroX/',\n]\n\nfor pth in package_paths:\n    sys.path.append(pth)","metadata":{"execution":{"iopub.status.busy":"2023-02-23T02:31:26.565019Z","iopub.execute_input":"2023-02-23T02:31:26.565372Z","iopub.status.idle":"2023-02-23T02:31:26.570809Z","shell.execute_reply.started":"2023-02-23T02:31:26.565341Z","shell.execute_reply":"2023-02-23T02:31:26.569860Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\nimport numpy as np\nfrom copy import deepcopy\nfrom pathlib import Path\nfrom collections import OrderedDict\nfrom IPython.display import clear_output","metadata":{"execution":{"iopub.status.busy":"2023-02-23T02:31:26.572785Z","iopub.execute_input":"2023-02-23T02:31:26.573754Z","iopub.status.idle":"2023-02-23T02:31:26.585716Z","shell.execute_reply.started":"2023-02-23T02:31:26.573722Z","shell.execute_reply":"2023-02-23T02:31:26.583776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\ntorch.__version__","metadata":{"execution":{"iopub.status.busy":"2023-02-23T02:31:26.587441Z","iopub.execute_input":"2023-02-23T02:31:26.587782Z","iopub.status.idle":"2023-02-23T02:31:26.599279Z","shell.execute_reply.started":"2023-02-23T02:31:26.587755Z","shell.execute_reply":"2023-02-23T02:31:26.597751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random","metadata":{"execution":{"iopub.status.busy":"2023-02-23T02:31:26.600763Z","iopub.execute_input":"2023-02-23T02:31:26.601123Z","iopub.status.idle":"2023-02-23T02:31:26.609479Z","shell.execute_reply.started":"2023-02-23T02:31:26.601088Z","shell.execute_reply":"2023-02-23T02:31:26.608112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def set_seed(seed):\n    \n    torch.backends.cudnn.benchmark = False\n    torch.backends.cudnn.deterministic = True\n    torch.use_deterministic_algorithms(True)\n    \n    random.seed(seed)\n    torch.manual_seed(seed)\n\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    np.random.seed(seed)\n\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    \n    \nset_seed(seed)","metadata":{"execution":{"iopub.status.busy":"2023-02-23T02:31:26.610988Z","iopub.execute_input":"2023-02-23T02:31:26.611820Z","iopub.status.idle":"2023-02-23T02:31:26.621282Z","shell.execute_reply.started":"2023-02-23T02:31:26.611777Z","shell.execute_reply":"2023-02-23T02:31:26.620330Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.set_num_threads(1)","metadata":{"execution":{"iopub.status.busy":"2023-02-23T02:31:26.623475Z","iopub.execute_input":"2023-02-23T02:31:26.623877Z","iopub.status.idle":"2023-02-23T02:31:26.636896Z","shell.execute_reply.started":"2023-02-23T02:31:26.623845Z","shell.execute_reply":"2023-02-23T02:31:26.635605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_path = '/kaggle/input/taiga-pos'\npath_work = '/kaggle/working/'","metadata":{"execution":{"iopub.status.busy":"2023-02-23T02:31:26.640970Z","iopub.execute_input":"2023-02-23T02:31:26.641408Z","iopub.status.idle":"2023-02-23T02:31:26.646971Z","shell.execute_reply.started":"2023-02-23T02:31:26.641371Z","shell.execute_reply":"2023-02-23T02:31:26.646057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from NeuroX.neurox.data.extraction import transformers_extractor","metadata":{"execution":{"iopub.status.busy":"2023-02-23T02:31:26.648040Z","iopub.execute_input":"2023-02-23T02:31:26.648737Z","iopub.status.idle":"2023-02-23T02:31:27.383555Z","shell.execute_reply.started":"2023-02-23T02:31:26.648701Z","shell.execute_reply":"2023-02-23T02:31:27.382545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Конвертируем файл, который получили из Probing_framework (уже получили, не в этом ноутбуке)","metadata":{}},{"cell_type":"code","source":"data_seed = 12345","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ConvertSample:\n    \"\"\"\"\n    Gets .csv files, makes train & test split in .txt format, trying to balance data.\n    \"\"\"\n    \n    def __init__(self, path, train_size=2500, test_size=900, shuffle: bool = True): \n\n        self.shuffle = shuffle\n        self.path = path\n        self.project_path = str(Path(os.getcwd()).parents[0])\n        self.category = re.search(r'[a-zA-Z]+_[a-zA-Z]+(?=.csv)', path)[0]\n        self.train_size = train_size\n        self.test_size = test_size\n        \n\n    def read(self) -> list: \n        with open(self.path, encoding=\"utf-8\") as f:\n            lines = [line.split('\\t') for line in f]\n            \n            if self.shuffle:\n                random.seed(data_seed)\n                random.shuffle(lines)\n                \n        return lines\n    \n    def stupid_cycle(self, values, dct, number) -> dict: #util для семплинга\n        \n        dict_filter = OrderedDict()\n        \n        for value in values:\n            i = 0\n            for k, v in dct.items():\n                if v == value:\n                    if i < number:\n                        dict_filter[k] = v\n                        i+=1\n            \n        return dict_filter\n    \n    \n    def stupid_test(self, values, dct) -> dict: #util для семплинга\n        \n        dict_filter = OrderedDict()\n        \n        for value in values:\n            i = 0\n            for k, v in dct.items():\n                if v == value:\n                    dict_filter[k] = v\n                    \n        return dict_filter\n                \n    def stupid_sampler(self) -> dict: #семплинг данных\n        \n        sents = self.read()\n        values_train = []\n        values_test = []\n        sents_train = []\n        sents_test = []\n\n        for line in sents:\n            part, value, sentence = line[0], line[1], line[2]\n            if 2 < len(sentence.split()) < 35:\n                if part == 'tr':\n                    if sentence not in sents_train:\n                        values_train.append(value)\n                        sents_train.append(sentence)\n                    \n                if part == 'te' or part== 'va':\n                    if sentence not in sents_train and sentence not in sents_test:\n                        values_test.append(value)\n                        sents_test.append(sentence)\n        \n        \n        train_dict = OrderedDict(zip(sents_train, values_train))\n        test_dict = OrderedDict(zip(sents_test, values_test))\n\n        A = set(values_train)\n        B = set(values_test)\n        values = sorted(list(A.intersection(B)))\n        \n        length = len(values)\n            \n        number_one = round(self.train_size/length)\n\n        dict_filter_train = self.stupid_cycle(values, train_dict, number_one)\n        dict_filter_test = self.stupid_test(values, test_dict)\n            \n        return dict_filter_train, dict_filter_test\n\n    def permute(self, dct) -> dict: # перемешивает словарь данных\n        \n        l = list(dct.items())\n        random.seed(data_seed)\n        random.shuffle(l)\n        return OrderedDict(l)\n        \n    def using_shuffle(self, a):\n        \n        keys = list(a.keys())\n        values = list(a.values())\n        random.seed(data_seed)\n        random.shuffle(values)\n        d = OrderedDict(zip(keys, values))\n        return d\n\n    def create_dicts(self):\n        \n        dict_filter_train, dict_filter_test = self.stupid_sampler()\n\n        if self.shuffle:\n            dict_filter_train = self.permute(dict_filter_train)\n            dict_filter_test = self.permute(dict_filter_test)\n        \n        dict_control_task = dict_filter_train.copy()\n        dict_control_task = self.using_shuffle(dict_control_task)\n\n        return dict_filter_train, dict_filter_test, dict_control_task\n\n\n    def create_paths(self) -> str:\n        \n        if re.search(r'(?<=\\/)[a-zA-Z][a-zA-Z]_[a-zA-Z]+(?=_)', self.path)[0]:\n            dataset = re.search(r'(?<=\\/)[a-zA-Z][a-zA-Z]_[a-zA-Z]+(?=_)', self.path)[0]\n            path = path_work+f'/large_data_{dataset}'\n        else:\n            path = path_work+'/large_data'\n            \n        if not os.path.isdir(path):\n            os.mkdir(path)\n            \n        if not os.path.isdir(path+f'/data_{self.category}'):\n            os.mkdir(path+f'/data_{self.category}')\n        \n        result_path_datatrain = path+f\"/data_{self.category}/datatrain_{self.category}.txt\"\n        result_path_labeltrain = path+f\"/data_{self.category}/labeltrain_{self.category}.txt\"\n        \n        result_path_cdatatrain = path+f\"/data_{self.category}/cdatatrain_{self.category}.txt\"\n        result_path_clabeltrain = path+f\"/data_{self.category}/clabeltrain_{self.category}.txt\"\n        \n        result_path_datatest = path+f\"/data_{self.category}/datatest_{self.category}.txt\"\n        result_path_labeltest = path+f\"/data_{self.category}/labeltest_{self.category}.txt\"\n\n        return result_path_datatrain, result_path_labeltrain, result_path_cdatatrain, result_path_clabeltrain, \\\n               result_path_datatest, result_path_labeltest\n\n\n    def writer(self) -> str: \n        \"\"\"\n        Writes to a file\n        \"\"\"\n        result_datatrain, result_labeltrain, result_cdatatrain, result_clabeltrain, result_datatest, result_labeltest = self.create_paths()\n       \n        \n        dict_filter_train, dict_filter_test, dict_control_task = self.create_dicts()\n\n        with open(result_datatrain, \"w\", encoding=\"utf-8\") as traindata, \\\n             open(result_labeltrain, \"w\", encoding=\"utf-8\") as trainlabel, \\\n             open(result_cdatatrain, \"w\", encoding=\"utf-8\") as ctraindata, \\\n             open(result_clabeltrain, \"w\", encoding=\"utf-8\") as ctrainlabel, \\\n             open(result_datatest, \"w\", encoding=\"utf-8\") as testdata, \\\n             open(result_labeltest, \"w\", encoding=\"utf-8\") as testlabel:\n            \n    \n            for sentence, value in dict_filter_train.items():\n                traindata.writelines(sentence)\n                trainlabel.writelines(value + '\\n')\n\n            for sentence, value in dict_control_task .items():\n                ctraindata.writelines(sentence)\n                ctrainlabel.writelines(value + '\\n')\n\n\n            for sentence, value in dict_filter_test.items():\n                testdata.writelines(sentence)\n                testlabel.writelines(value + '\\n')\n                                                                  \n        \n        return result_datatrain, result_labeltrain, result_cdatatrain, result_clabeltrain, result_datatest, result_labeltest\n        \n\n\nclass GetEmbeddings:\n    \"\"\"\"\n    Receives .txt files with sentences and computes embeddings for them.\n    \"\"\"\n    \n    def __init__(self, path_trdata, path_tedata):\n        \n        self.path_trdata = path_trdata\n        self.path_tedata = path_tedata\n        \n        self.category = re.search(r'[a-zA-Z]+_[a-zA-Z]+(?=.txt)', path_trdata)[0]\n        self.dataset = re.search(r'(?<=_)[a-zA-Z]+_[a-zA-Z]+(?=\\/)', path_trdata)[0]\n        \n    def jsons(self, model):\n        \n        path = path_work + f'/large_data_{self.dataset}/data_{self.category}'\n        \n        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n        print('Using device:', device)\n        print()\n        \n        transformers_extractor.extract_representations(model,\n        self.path_trdata,\n        path+'/activations_train.json',\n        aggregation=\"average\", #last, first   \n        device=device                                            \n        )\n        \n        clear_output(wait=False)\n        print('Using device:', device)\n        print()\n        \n        transformers_extractor.extract_representations(model,\n        self.path_tedata,\n        path+'/activations_te.json',\n        aggregation=\"average\", #last, first\n        device=device                                               \n        )\n        clear_output(wait=False)","metadata":{"execution":{"iopub.status.busy":"2023-02-23T02:31:27.384795Z","iopub.execute_input":"2023-02-23T02:31:27.385097Z","iopub.status.idle":"2023-02-23T02:31:27.418550Z","shell.execute_reply.started":"2023-02-23T02:31:27.385070Z","shell.execute_reply":"2023-02-23T02:31:27.417021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"https://neurox.qcri.org/docs/neurox.data.extraction.html?highlight=extract_representations#neurox.data.extraction.transformers_extractor.extract_representations","metadata":{}},{"cell_type":"code","source":"import pickle\nfrom NeuroX.neurox.data import loader as data_loader\nfrom NeuroX.neurox.interpretation import utils\nfrom NeuroX.neurox.interpretation import ablation\nfrom NeuroX.neurox.interpretation import linear_probe","metadata":{"execution":{"iopub.status.busy":"2023-02-23T02:31:27.419927Z","iopub.execute_input":"2023-02-23T02:31:27.420339Z","iopub.status.idle":"2023-02-23T02:31:28.242786Z","shell.execute_reply.started":"2023-02-23T02:31:27.420288Z","shell.execute_reply":"2023-02-23T02:31:28.241579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_sentence_data(source_path, labels_path, activations): \n    \n    #тут немного переписали функцию потому что в библиотеке ошибка!!!\n\n    tokens = {\"source\": [], \"target\": []}\n\n    with open(source_path) as source_fp:\n        for line_idx, line in enumerate(source_fp):\n            line_tokens = line.strip().split() #вот тут переписано\n            tokens[\"source\"].append(line_tokens) #и тут\n\n    with open(labels_path) as labels_fp:\n        for line in labels_fp:\n            line_tokens = line.strip().split()\n            tokens[\"target\"].append(line_tokens)\n\n    assert len(tokens[\"source\"]) == len(tokens[\"target\"]), (\n        \"Number of lines do not match (source: %d, target: %d)!\"\n        % (len(tokens[\"source\"]), len(tokens[\"target\"]))\n    )\n\n    assert len(activations) == len(tokens[\"source\"]), (\n        \"Number of lines do not match (activations: %d, source: %d)!\"\n        % (len(activations), len(tokens[\"source\"]))\n    )\n\n    \n    for idx, activation in enumerate(activations):\n        assert activation.shape[0] == len(tokens[\"source\"][idx])\n\n    return tokens","metadata":{"execution":{"iopub.status.busy":"2023-02-23T02:31:28.244561Z","iopub.execute_input":"2023-02-23T02:31:28.244897Z","iopub.status.idle":"2023-02-23T02:31:28.254145Z","shell.execute_reply.started":"2023-02-23T02:31:28.244870Z","shell.execute_reply":"2023-02-23T02:31:28.252684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\nfrom torch.autograd import Variable\n\n\ndef _numpyfy(x):\n    if isinstance(x, np.ndarray):\n        return x\n    return np.array(x)\n\n\ndef accuracy(preds, labels):\n    preds = _numpyfy(preds)\n    labels = _numpyfy(labels)\n    return (preds == labels).mean()\n\n\nclass LinearProbe(nn.Module):\n    \"\"\"Torch model for linear probe\"\"\"\n    \n    def __init__(self, input_size, num_classes):\n        \"\"\"Initialize a linear model\"\"\"\n        super(LinearProbe, self).__init__()\n        self.linear = nn.Linear(input_size, num_classes)\n\n    def forward(self, x):\n        \"\"\"Run a forward pass on the model\"\"\"\n        out = self.linear(x)\n        return out\n\ndef l1_penalty(var):\n    return torch.abs(var).sum()\n\n\ndef l2_penalty(var):\n    return torch.sqrt(torch.pow(var, 2).sum())\n\n\ndef _train_probe(\n    X_train,\n    y_train,\n    task_type,\n    lambda_l1=0,\n    lambda_l2=0,\n    num_epochs=10,\n    batch_size=32,\n    learning_rate=0.001,\n    ):\n\n    progressbar = utils.get_progress_bar()\n    print(\"Training %s probe\" % (task_type))\n    # Check if we can use GPU's for training\n    use_gpu = torch.cuda.is_available()\n\n    if lambda_l1 is None or lambda_l2 is None:\n        raise ValueError(\"Regularization weights cannot be None\")\n\n    print(\"Creating model...\")\n    if task_type == \"classification\":\n        num_classes = len(set(y_train))\n        if num_classes <= 1:\n            raise ValueError(\n                \"Classification problem must have more than one target class\"\n            )\n    else:\n        num_classes = 1\n    print(\"Number of training instances:\", X_train.shape[0])\n    if task_type == \"classification\":\n        print(\"Number of classes:\", num_classes)\n    set_seed(seed)\n    probe = LinearProbe(X_train.shape[1], num_classes)\n    if use_gpu:\n        probe = probe.cuda()\n\n    if task_type == \"classification\":\n        criterion = nn.CrossEntropyLoss()\n    elif task_type == \"regression\":\n        criterion = nn.MSELoss()\n    else:\n        raise ValueError(\"Invalid `task_type`\")\n    \n    set_seed(seed)\n    optimizer = torch.optim.Adam(probe.parameters(), lr=learning_rate)\n\n    X_tensor = torch.from_numpy(X_train)\n    y_tensor = torch.from_numpy(y_train)\n\n    for epoch in range(num_epochs):\n        num_tokens = 0\n        avg_loss = 0\n        for inputs, labels in progressbar(\n            utils.batch_generator(X_tensor, y_tensor, batch_size=batch_size),\n            desc=\"epoch [%d/%d]\" % (epoch + 1, num_epochs),\n        ):\n            num_tokens += inputs.shape[0]\n            if use_gpu:\n                inputs = inputs.cuda()\n                labels = labels.cuda()\n            inputs = inputs.float()\n            inputs = Variable(inputs)\n            labels = Variable(labels)\n\n            # Forward + Backward + Optimize\n            set_seed(seed)\n            optimizer.zero_grad()\n\n            outputs = probe(inputs)\n            \n            if task_type == \"regression\":\n                outputs = outputs.squeeze()\n                \n            weights = list(probe.parameters())[0]\n            \n            set_seed(seed)\n            loss = (\n                criterion(outputs, labels)\n                + lambda_l1 * l1_penalty(weights)\n                + lambda_l2 * l2_penalty(weights)\n            )\n            \n            set_seed(seed)\n            loss.backward()\n            \n            set_seed(seed)\n            optimizer.step()\n\n            avg_loss += loss.item()\n\n        print(\n            \"Epoch: [%d/%d], Loss: %.4f\"\n            % (epoch + 1, num_epochs, avg_loss / num_tokens)\n        )\n\n    return probe\n\n\ndef train_logistic_regression_probe(\n    X_train,\n    y_train,\n    lambda_l1=0,\n    lambda_l2=0,\n    num_epochs=10,\n    batch_size=32,\n    learning_rate=0.001,\n    ):\n\n    return _train_probe(\n        X_train,\n        y_train,\n        task_type=\"classification\",\n        lambda_l1=lambda_l1,\n        lambda_l2=lambda_l2,\n        num_epochs=num_epochs,\n        batch_size=batch_size,\n        learning_rate=learning_rate,\n    )\n\ndef compute_score(preds, labels, metric):\n\n    if metric == \"accuracy\":\n        return accuracy(preds, labels)\n\n\ndef evaluate_probe(\n    probe,\n    X,\n    y,\n    idx_to_class=None,\n    return_predictions=False,\n    source_tokens=None,\n    batch_size=32,\n    metric=\"accuracy\",\n    ):\n \n    progressbar = utils.get_progress_bar()\n\n    # Check if we can use GPU's for evaluation\n    use_gpu = torch.cuda.is_available()\n\n    if use_gpu:\n        probe = probe.cuda()\n\n    # always evaluate in full precision\n    probe = probe.float()\n\n    # Test the Model\n    y_pred = []\n\n    def source_generator():\n        for s in source_tokens:\n            for t in s:\n                yield t\n\n    src_words = source_generator()\n\n    if return_predictions:\n        predictions = []\n        src_word = -1\n\n    for inputs, labels in progressbar(\n        utils.batch_generator(\n            torch.from_numpy(X), torch.from_numpy(y), batch_size=batch_size\n        ),\n        desc=\"Evaluating\",\n        ):\n        if use_gpu:\n            inputs = inputs.cuda()\n            labels = labels.cuda()\n\n        # always evaluate in full precision\n        inputs = inputs.float()\n\n        inputs = Variable(inputs)\n        labels = Variable(labels)\n\n        outputs = probe(inputs)\n\n        if outputs.data.shape[1] == 1:\n            # Regression\n            predicted = outputs.data\n        else:\n            # Classification\n            _, predicted = torch.max(outputs.data, 1)\n        predicted = predicted.cpu().numpy()\n\n        for i in range(0, len(predicted)):\n            idx = predicted[i]\n            if idx_to_class:\n                key = idx_to_class[idx]\n            else:\n                key = idx\n\n            y_pred.append(predicted[i])\n\n            if return_predictions:\n                if source_tokens:\n                    src_word = next(src_words)\n                else:\n                    src_word = src_word + 1\n                predictions.append((src_word, key, labels[i].item() == idx))\n\n    y_pred = np.array(y_pred)\n\n    result = compute_score(y_pred, y, metric)\n\n    print(\"Score (%s) of the probe: %0.2f\" % (metric, result))\n\n    class_scores = {}\n    class_scores[\"__OVERALL__\"] = result\n\n    if idx_to_class:\n        for i in idx_to_class:\n            class_name = idx_to_class[i]\n            class_instances_idx = np.where(y == i)[0]\n            y_pred_filtered = y_pred[class_instances_idx]\n            y_filtered = y[class_instances_idx]\n            total = y_filtered.shape\n            if total == 0:\n                class_scores[class_name] = 0\n            else:\n                class_scores[class_name] = compute_score(\n                    y_pred_filtered, y_filtered, metric\n                )\n\n    if return_predictions:\n        return class_scores, predictions\n    return class_scores\n","metadata":{"execution":{"iopub.status.busy":"2023-02-23T02:31:28.256708Z","iopub.execute_input":"2023-02-23T02:31:28.257179Z","iopub.status.idle":"2023-02-23T02:31:28.287706Z","shell.execute_reply.started":"2023-02-23T02:31:28.257143Z","shell.execute_reply":"2023-02-23T02:31:28.286334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Experiment:\n    \n    \n    def __init__(self, path_trdata, path_trlabel, path_tedata, path_telabel):\n\n        #некрасиво инициализирована куча переменных для функций\n        \n        self.path_trdata = path_trdata\n        self.path_trlabel = path_trlabel\n        self.path_tedata = path_tedata\n        self.path_telabel = path_telabel\n        self.category = re.search(r'[a-zA-Z]+_[a-zA-Z]+(?=.txt)', path_trdata)[0]\n        self.dataset = re.search(r'(?<=_)[a-zA-Z]+_[a-zA-Z]+(?=\\/)', path_trdata)[0]\n        \n        self.path = path_work+f'large_data_{self.dataset}/data_{self.category}'\n        \n        self.activations_tr, self.num_layers = data_loader.load_activations(self.path+'/activations_train.json', 768)\n        self.activations_te, self.num_layers = data_loader.load_activations(self.path+'/activations_te.json', 768)\n        \n        self.tokens_tr = load_sentence_data(self.path_trdata, self.path_trlabel, self.activations_tr)\n        self.tokens_te = load_sentence_data(self.path_tedata, self.path_telabel, self.activations_te)\n        \n        self.X_tr, self.y_tr, mp = utils.create_tensors(self.tokens_tr, self.activations_tr, 'Nom')\n        self.label2idx, self.idx2label, self.src2idx, self.idx2src = mp\n\n        self.X_te, self.y_te, mapping = utils.create_tensors(self.tokens_te, self.activations_te, 'Nom', mappings = mp)\n    \n\n        \n    def run_classification(self):#just пробинг\n           \n        probe = train_logistic_regression_probe(self.X_tr, self.y_tr, lambda_l1=0.003, lambda_l2=0.003, batch_size=64)\n        scores_tr = evaluate_probe(probe, self.X_tr, self.y_tr, idx_to_class=self.idx2label, batch_size=64)\n        scores_te = evaluate_probe(probe, self.X_te, self.y_te, idx_to_class=self.idx2label, batch_size=64)\n        return probe, scores_tr, scores_te\n    \n    def nranking(self, probe): #тут топ нейроны\n\n        ordering, cutoffs = linear_probe.get_neuron_ordering(probe, self.label2idx, search_stride=99)\n        return ordering, cutoffs\n    \n    def top_n(self, probe, percentage=0.1):\n\n        return linear_probe.get_top_neurons(probe, percentage, self.label2idx) #return np.array(list(top_neurons_union)), top_neurons (dict)\n    \n    def threshold_n(self, probe, fraction=2):\n        return linear_probe.get_top_neurons_hard_threshold(probe, fraction, self.label2idx) #np.array(list(top_neurons_union)), top_neurons\n    \n    def keep_bottom(self, neurons):\n        X_tr_b = deepcopy(self.X_tr)\n        X_te_b = deepcopy(self.X_te)\n        X_tr_selected = ablation.filter_activations_remove_neurons(X_tr_b, neurons)\n        probe_selected = linear_probe.train_logistic_regression_probe(X_tr_selected, self.y_tr, lambda_l1=0.003, lambda_l2=0.003)\n        scores_tr = linear_probe.evaluate_probe(probe_selected, X_tr_selected, self.y_tr, idx_to_class=self.idx2label)\n        X_te_selected = ablation.filter_activations_remove_neurons(X_te_b, neurons)\n        scores_te = linear_probe.evaluate_probe(probe_selected, X_te_selected, self.y_te, idx_to_class=self.idx2label)\n        return scores_tr, scores_te\n    \n    def keep_util(self, neurons, X_tr, X_te):\n        X_tr_selected = ablation.filter_activations_keep_neurons(X_tr, neurons)\n        probe_selected = linear_probe.train_logistic_regression_probe(X_tr_selected, self.y_tr, lambda_l1=0.003, lambda_l2=0.003)\n        scores_tr = linear_probe.evaluate_probe(probe_selected, X_tr_selected, self.y_tr, idx_to_class=self.idx2label)\n        X_te_selected = ablation.filter_activations_keep_neurons(X_te, neurons)\n        scores_te = linear_probe.evaluate_probe(probe_selected, X_te_selected, self.y_te, idx_to_class=self.idx2label)\n        return scores_tr, scores_te\n    \n    def return_weights(self, probe):\n        weights1 = list(probe.parameters())[0].data.cpu()\n        weights2 = np.abs(weights1.numpy())\n        return weights1, weights2\n        \n    def keep_only(self, neurons, goal='top'):\n       \n        if goal == 'top':\n            X_tr_top = deepcopy(self.X_tr)\n            X_te_top = deepcopy(self.X_te)\n            return self.keep_util(neurons, X_tr_top, X_te_top)\n            \n        elif goal == 'threshold':\n            X_tr_t = deepcopy(self.X_tr)\n            X_te_t = deepcopy(self.X_te)\n            return self.keep_util(neurons, X_tr_t, X_te_t)  \n        \n        \n    def data_size(self):\n        return self.X_tr.shape[0], self.X_te.shape[0], len(set(self.y_te))","metadata":{"execution":{"iopub.status.busy":"2023-02-23T02:31:28.289798Z","iopub.execute_input":"2023-02-23T02:31:28.290958Z","iopub.status.idle":"2023-02-23T02:31:28.311396Z","shell.execute_reply.started":"2023-02-23T02:31:28.290905Z","shell.execute_reply":"2023-02-23T02:31:28.310284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for dirname, _, filenames in os.walk(data_path):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2023-02-23T02:31:28.313065Z","iopub.execute_input":"2023-02-23T02:31:28.313464Z","iopub.status.idle":"2023-02-23T02:31:28.340224Z","shell.execute_reply.started":"2023-02-23T02:31:28.313438Z","shell.execute_reply":"2023-02-23T02:31:28.339571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ordered_neurons = {}\nthreshold = {}\nthreshold_c = {}\nweights = {}\n\ntop_n = {}\ntop_n_c = {}\n\nbottom_n = {}\n# bottom_n2 = {}\n\nscores = {}\nscores_control = {}\n\nsize = {}\n\nscores_keep_top = {}\nscores_keep_top_c = {}\n\nscores_keep_thres = {}\nscores_keep_thres_c = {}\n\nscores_keep_bot = {}\n# scores_keep_bot2 = {}\n\n\n\n\nfor dirname, _, filenames in os.walk(data_path):\n    for filename in filenames:\n        file = os.path.join(dirname, filename)\n\n        splitter = ConvertSample(file)\n\n        #получаем трейновую и тестовую выборку\n        path_trdata, path_trlabel,path_ctrdata, path_ctrlabel, path_tedata, path_telabel = splitter.writer()\n        #получаем эмбеддинги\n        data = GetEmbeddings(path_trdata, path_tedata)\n        data.jsons('bert-base-multilingual-uncased')\n        cat = Experiment(path_trdata, path_trlabel, path_tedata, path_telabel)    \n        cat_name = re.search(r'[a-zA-Z]+_[a-zA-Z]+(?=.txt)', path_trdata)[0]\n        d_name = cat.dataset\n        X_tr_shape, X_te_shape, n_class = cat.data_size()\n        size[cat_name] = [X_tr_shape, X_te_shape, n_class]\n        \n        probe, scores_tr, scores_te = cat.run_classification() # просто классификация\n        scores[cat_name] = [scores_tr, scores_te]\n        weights1, weights2 = cat.return_weights(probe)\n        weights[cat_name] = [weights1, weights2]\n        \n        ordering, cutoffs = cat.nranking(probe) # ранжирование\n        ordered_neurons[cat_name] = [ordering, cutoffs]\n        \n        top_n[cat_name] = cat.top_n(probe)[0] \n        scores_tr, scores_te = cat.keep_only(neurons=top_n[cat_name], goal='top') \n        scores_keep_top[cat_name] = [scores_tr, scores_te] # на топ процентов\n        \n        bottom_n[cat_name] = cat.top_n(probe, percentage=0.9)[0]\n        scores_tr, scores_te = cat.keep_bottom(neurons=bottom_n[cat_name])\n        scores_keep_bot[cat_name] = [scores_tr, scores_te]   # на bottom процентов\n        \n#         bottom_n2[cat_name] = cat.top_n(probe, percentage=0.98)[0]\n#         scores_tr, scores_te = cat.keep_bottom(neurons=bottom_n2[cat_name])\n#         scores_keep_bot2[cat_name] = [scores_tr, scores_te]   # на bottom процентов\n        \n        \n        threshold[cat_name] = cat.threshold_n(probe)[0] \n        scores_tr, scores_te = cat.keep_only(threshold[cat_name], goal='threshold') \n        scores_keep_thres[cat_name] = [scores_tr, scores_te] # с трешхолдом\n        \n        \n        with open(f'scores_{d_name}.pkl', 'wb') as f:\n            pickle.dump(scores, f)\n            \n        with open(f'neurons_{d_name}.pkl', 'wb') as f:\n            pickle.dump(ordered_neurons, f)\n        \n        with open(f'weights_{d_name}.pkl', 'wb') as f:\n            pickle.dump(weights, f)\n            \n        with open(f'scores_keep_top_{d_name}.pkl', 'wb') as f:\n            pickle.dump(scores_keep_top, f)\n            \n        with open(f'scores_keep_thres_{d_name}.pkl', 'wb') as f:\n            pickle.dump(scores_keep_thres, f)\n            \n        with open(f'scores_keep_bot_{d_name}.pkl', 'wb') as f:\n            pickle.dump(scores_keep_bot, f)\n            \n#         with open(f'scores_keep_bot2_{d_name}.pkl', 'wb') as f:\n#             pickle.dump(scores_keep_bot2, f)\n            \n        with open(f'top_n_{d_name}.pkl', 'wb') as f:\n            pickle.dump(top_n, f)\n            \n        with open(f'bottom_n_{d_name}.pkl', 'wb') as f:\n            pickle.dump(bottom_n, f)\n            \n#         with open(f'bottom_n2_{d_name}.pkl', 'wb') as f:\n#             pickle.dump(bottom_n2, f)\n            \n        with open(f'threshold_{d_name}.pkl', 'wb') as f:\n            pickle.dump(threshold, f)\n            \n        with open(f'size_{d_name}.pkl', 'wb') as f:\n            pickle.dump(size, f)\n            \n        cat = Experiment(path_ctrdata, path_ctrlabel, path_tedata, path_telabel)    \n        cat_name = re.search(r'[a-zA-Z]+_[a-zA-Z]+(?=.txt)', path_trdata)[0]\n        \n        probe, scores_tr, scores_te = cat.run_classification()\n        scores_control[cat_name] = [scores_tr, scores_te]\n        \n        top_n_c[cat_name] = cat.top_n(probe)[0] \n        scores_tr, scores_te = cat.keep_only(neurons=top_n_c[cat_name], goal='top')\n        scores_keep_top_c[cat_name] = [scores_tr, scores_te] # на топ процентов\n        \n        threshold_c[cat_name] = cat.threshold_n(probe)[0] \n        scores_tr, scores_te = cat.keep_only(threshold_c[cat_name], goal='threshold') \n        scores_keep_thres_c[cat_name] = [scores_tr, scores_te] # с трешхолдом\n        \n        with open(f'scores_c_{d_name}.pkl', 'wb') as f:\n            pickle.dump(scores_control, f)\n        \n        with open(f'scores_keep_top_c_{d_name}.pkl', 'wb') as f:\n            pickle.dump(scores_keep_top_c, f)\n            \n        with open(f'scores_keep_thres_c_{d_name}.pkl', 'wb') as f:\n            pickle.dump(scores_keep_thres_c, f)\n         \n\n\n        dir_to_delete = f'/kaggle/working/large_data_{d_name}/data_{cat_name}/' \n        with os.scandir(dir_to_delete) as entries:\n            for entry in entries:\n                file_to_delete = f\"{dir_to_delete}{entry.name}\"\n                print(file_to_delete)\n                os.remove(file_to_delete)","metadata":{"execution":{"iopub.status.busy":"2023-02-23T02:31:28.341325Z","iopub.execute_input":"2023-02-23T02:31:28.341858Z","iopub.status.idle":"2023-02-23T02:46:21.445840Z","shell.execute_reply.started":"2023-02-23T02:31:28.341832Z","shell.execute_reply":"2023-02-23T02:46:21.444794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores","metadata":{"execution":{"iopub.status.busy":"2023-02-23T02:46:21.447267Z","iopub.execute_input":"2023-02-23T02:46:21.447952Z","iopub.status.idle":"2023-02-23T02:46:21.457915Z","shell.execute_reply.started":"2023-02-23T02:46:21.447918Z","shell.execute_reply":"2023-02-23T02:46:21.456928Z"},"trusted":true},"execution_count":null,"outputs":[]}]}